#!/usr/bin/env python
import numpy as np
import numpy.ma as ma
import math
import time, threading
import operator
import random
import json

import rospy
from freeplay_sandbox_msgs.msg import DiscreteAction, ListFloatStamped 
from std_msgs.msg import String
import signal, sys
import os

DEBUG = False

class Actor(object):
    def __init__(self):
        self._state_sub = rospy.Subscriber("sparc/state", ListFloatStamped, self.on_state)
        self._trigger_state_sub = rospy.Subscriber("sparc/trigger_state", ListFloatStamped, self.on_trigger_state)
        self._action_sub = rospy.Subscriber("sparc/rewarded_action_dis",DiscreteAction, self.on_action)
        self._event_sub = rospy.Subscriber("sparc/event", String, self.on_event)

        self._action_pub = rospy.Publisher("sparc/proposed_action_dis", DiscreteAction, queue_size = 5)
        self._actions = []
        self._trigger_states = []

        self._has_moved = False
        self._moving_Timer = threading.Timer(10, self.reset_has_moved)
        self._state = None
        self._proposed_action = None

        self._use_files = rospy.get_param('~use_file',False)
        print "using files " + str(self._use_files)
        if self._use_files:
            try:
                self.load_json()
            except Exception:
                pass

    def on_state(self, message):
        self._state = np.array(message.data)
        ##print self._state

    def on_trigger_state(self, message):
        self._trigger_state = np.array(message.data)
#        print self._trigger_state
        if self._trigger_state[-3]%4 == 0:
            self.select_action()

        #if self._trigger_state[-3]%4 == 0:
        #    self.select_action()

    def on_event(self, message):
        if message.data == "select":
            self.select_action()

    def on_action(self, message):
        #print "received action"
        action = message.action_id
        reward = message.reward
        state_mask = np.array(message.state_mask,dtype = bool)
        masked_state = ma.array(self._state, mask = ~state_mask, dtype = float)
        if DEBUG:
            print "masked state"
            print masked_state

        self.add_point(action, masked_state, reward)

        if len(message.trigger_mask) > 0:
            trigger_mask = np.array(message.trigger_mask)
            masked_trigger_state = ma.array(self._trigger_state, mask = ~trigger_mask, dtype = float)
            self._trigger_states.append(masked_trigger_state)
        self._proposed_action = None
    
    # Similarity (euclidian distance normalised by the number of defined dimensions)
    # with x a masked state and y a normal one
    def get_similarity_states(self, x, y):
        if DEBUG:
            print x - y
        #similarity = 1 - math.sqrt(np.sum((x-y)*(x-y)))/sum(~x.mask)
        similarity = 1 - (np.sum((x-y)*(x-y)))/sum(~x.mask)
        if similarity is ma.masked:
            similarity = 0.5
        return similarity

    def select_action(self):
        #if DEBUG:
        print "selecting action"
        #print self._state
        if len(self._actions) == 0:
            return
        weighted_rewards = np.zeros(len(self._actions))
        indexes = np.zeros(len(self._actions),dtype=int)
        for i, action in enumerate(self._actions):
            print action._action
            reward = 0
            index = 0
            max_similarity = 0
            for idx, state in enumerate(action._states):
                print idx
                print "state " + str(state)
                print "reward " + str(action._rewards[idx])
                print "similarity " + str(self.get_similarity_states(state, self._state))
                similarity = self.get_similarity_states(state, self._state)
                if (similarity > max_similarity):
                    max_similarity = similarity
                    reward = action._rewards[idx]
                    index = idx
            weighted_rewards[i] = reward * max_similarity
            indexes[i] = index
        print "rewards"
        print weighted_rewards
        if max(weighted_rewards)<=0:
            print "no good candidate"
            return
        index_selected_action = np.argmax(weighted_rewards)
        proposed_action = self._actions[index_selected_action]

        print "index"
        print index_selected_action
        print "indexes"
        print indexes[index_selected_action]

        mask = ~self._actions[index_selected_action]._states[indexes[index_selected_action]].mask

        message = DiscreteAction()
        message.header.frame_id = "sandtray"
        message.header.stamp = rospy.Time(0)
        message.action_id = self._actions[index_selected_action]._action
#        for i in action.mask:
#            message.maskAction.append(bool(not i))
        message.state_mask=mask

        self._action_pub.publish(message)
#        self._has_moved = True
#        self._moving_Timer.start()

#        self._reaction_timer = threading.Timer(2, self.select_action)

    def reset_has_moved(self):
        self._has_moved = False
        self._moving_Timer = threading.Timer(10, self.reset_has_moved)

    def run(self):
        rospy.spin()

    def signal_handler(self, signal, frame):
        if self._use_files:
            self.save_json()
        sys.exit()

    def save_json(self):
        data=[]
        for a in self._actions:
            action = {"id": a._action}
            points = []
            for idx, reward in enumerate(a._rewards):
                item={"s":a._states[idx].tolist(),"r":reward}
                points.append(item)
            action["points"]=points
            data.append(action)
        with open('/home/senft/data.json','w') as outfile:
            json.dump(data, outfile)
#
    def load_json(self):
        with open('/home/senft/data.json','r') as infile:
            data=json.load(infile)
            for a in data:
                id = a["id"]
                points = a["points"]
                for p in points:
                    m = (p["s"] == np.array(None))
                    d = np.where(p["s"] == np.array(None),0,p["s"])
                    print d
                    s=ma.array(d, mask=m)
                    self.add_point(id, s, p["r"])
                

    def add_point(self, action, state, reward):
        for known_action in self._actions:
            if known_action._action == action:
                known_action._states.append(state)
                known_action._rewards.append(reward)
                break
        else:
            new_action = Action(action, state, reward)
            self._actions.append(new_action)

class Action(object):
    def __init__(self, act, state, reward):
        self._action = act
        self._states = [state]
        self._rewards = [reward]

if __name__ == "__main__":
    rospy.init_node('actor')
    actor = Actor()
    signal.signal(signal.SIGINT, actor.signal_handler)
    actor.run()
